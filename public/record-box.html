<!-- The starting point for this project came from https://github.com/google-ar/three.ar.js/blob/master/examples/spawn-at-surface.html -->
<!-- Getting the Spotify API working came largely from https://github.com/spotify/web-api-auth-examples/tree/master/authorization_code -->


<!DOCTYPE html>
<html lang="en">
<head>
  <title>Record Box</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, user-scalable=no,
  minimum-scale=1.0, maximum-scale=1.0">
  <style>
    body {
      font-family: monospace;
      margin: 0;
      overflow: hidden;
      position: fixed;
      width: 100%;
      height: 100vh;
      -webkit-user-select: none;
      user-select: none;
    }
    #info {
      position: absolute;
      left: 50%;
      bottom: 0;
      transform: translate(-50%, 0);
      margin: 1em;
      z-index: 10;
      display: block;
      line-height: 2em;
      text-align: center;
      color: #fff;
      background-color: rgba(40, 40, 40, 0.4);
      padding: 0.4em 0.6em;
      border-radius: 0.1em;
    }

    #spotify-embed {
      position: absolute;
      visibility: hidden;
      left: 50%;
      top: 20px;
      z-index: 20;
      transform: translate(-50%, 0);
    }

    .links {
      background-color: rgba(40, 40, 40, 0.6);
      padding: 0.4em 0.6em;
      border-radius: 0.1em;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
  </style>
</head>
<body>
<div id="spotify-embed"></div>
<div id="info">
  Tap to place your record player on a surface.
</div>
<script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>
<script src="./js/three.js/three.js"></script>
<script src="./js/three.js/VRControls.js"></script>
<script src="./js/three.ar.js"></script>
<script src="./js/wood-box.js"></script>
<script src="./js/records.js"></script>
<script src="./js/selector.js"></script>
<script>

var vrDisplay;
var vrControls;
var arView;

var canvas;
var camera;
var scene;
var renderer;

var recordBox;
var woodBox;
var records;
var targetList = [];

var directionalLight;
var light;

var BOX_SIZE = 0.2;

/**
 * Use the `getARDisplay()` utility to leverage the WebVR API
 * to see if there are any AR-capable WebVR VRDisplays. Returns
 * a valid display if found. Otherwise, display the unsupported
 * browser message.
 */
THREE.ARUtils.getARDisplay().then(function (display) {
  if (display) {
    vrDisplay = display;
    addRecords(BOX_SIZE).then(
      function(recordsGroup){
        records = recordGroup;
        init();
      }
    );
  } else {
    THREE.ARUtils.displayUnsupportedMessage();
  }
});

function init() {

  // Setup the three.js rendering environment
  renderer = new THREE.WebGLRenderer({ alpha: true });
  renderer.setPixelRatio(window.devicePixelRatio);
  renderer.setSize(window.innerWidth, window.innerHeight);
  renderer.autoClear = false;
  canvas = renderer.domElement;
  document.body.appendChild(canvas);
  scene = new THREE.Scene();

  // Creating the ARView, which is the object that handles
  // the rendering of the camera stream behind the three.js
  // scene
  arView = new THREE.ARView(vrDisplay, renderer);

  // The ARPerspectiveCamera is very similar to THREE.PerspectiveCamera
  camera = new THREE.ARPerspectiveCamera(
    vrDisplay,
    60,
    window.innerWidth / window.innerHeight,
    vrDisplay.depthNear,
    vrDisplay.depthFar
  );

  directionalLight = new THREE.DirectionalLight();
  directionalLight.intensity = 0.3;
  directionalLight.position.set(10, 15, 10);
  // We want this light to cast shadow
  directionalLight.castShadow = true;
  light = new THREE.AmbientLight();
  scene.add(light);
  scene.add(directionalLight);


  woodBox = boxSetup(BOX_SIZE);

  recordBox = new THREE.Group();
  recordBox.add(woodBox, records);
  recordBox.position.set(10000, 10000, 10000);
  scene.add(recordBox);

  // VRControls is a utility from three.js that applies the device's
  // orientation/position to the perspective camera, keeping our
  // real world and virtual world in sync.
  vrControls = new THREE.VRControls(camera);

  // Bind our event handlers
  window.addEventListener('resize', onWindowResize, false);
  canvas.addEventListener('touchstart', createRecordBox, false);

  // Kick off the render loop!
  update();
}

/**
 * The render loop, called once per frame. Handles updating
 * our scene and rendering.
 */
function update() {
  // Clears color from the frame before rendering the camera (arView) or scene.
  renderer.clearColor();

  // Render the device's camera stream on screen first of all.
  // It allows to get the right pose synchronized with the right frame.
  arView.render();

  // Update our camera projection matrix in the event that
  // the near or far planes have updated
  camera.updateProjectionMatrix();

  // Update our perspective camera's positioning
  vrControls.update();

  // Render our three.js virtual scene
  renderer.clearDepth();
  renderer.render(scene, camera);

  // Kick off the requestAnimationFrame to call this function
  // when a new VRDisplay frame is rendered
  vrDisplay.requestAnimationFrame(update);
}

/**
 * On window resize, update the perspective camera's aspect ratio,
 * and call `updateProjectionMatrix` so that we can get the latest
 * projection matrix provided from the device
 */
function onWindowResize () {
  camera.aspect = window.innerWidth / window.innerHeight;
  camera.updateProjectionMatrix();
  renderer.setSize(window.innerWidth, window.innerHeight);
}

/**
 * When clicking on the screen, fire a ray from where the user clicked
 * on the screen and if a hit is found, place a cube there.
 */
function createRecordBox (e) {
  // If we don't have a touches object, abort
  // TODO: is this necessary?
  if (!e.touches[0]) {
    return;
  }

  // Inspect the event object and generate normalize screen coordinates
  // (between 0 and 1) for the screen position.
  var x = e.touches[0].pageX / window.innerWidth;
  var y = e.touches[0].pageY / window.innerHeight;

  // Send a ray from the point of click to the real world surface
  // and attempt to find a hit. `hitTest` returns an array of potential
  // hits.
  var hits = vrDisplay.hitTest(x, y);

  // If a hit is found, just use the first one
  if (hits && hits.length) {
    var hit = hits[0];
    // Use the `placeObjectAtHit` utility to position
    // the cube where the hit occurred
    THREE.ARUtils.placeObjectAtHit(recordBox,  // The object to place
                                   hit,   // The VRHit object to move the cube to
                                   1,     // Easing value from 0 to 1; we want to move
                                          // the cube directly to the hit position
                                   true); // Whether or not we also apply orientation


  canvas.removeEventListener('touchstart', createRecordBox, false);
  document.getElementById('info').innerHTML = 'Swipe up and down through albums. Tap to listen.';

  setTimeout(function(){
    swipedetect();
  }, 500);

  }


}
</script>
</body>
</html>
